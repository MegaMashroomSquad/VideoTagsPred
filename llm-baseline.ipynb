{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/MegaMashroomSquad/VideoTagsPred.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T16:31:53.923411Z","iopub.execute_input":"2024-09-28T16:31:53.923780Z","iopub.status.idle":"2024-09-28T16:31:55.647275Z","shell.execute_reply.started":"2024-09-28T16:31:53.923742Z","shell.execute_reply":"2024-09-28T16:31:55.645960Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'VideoTagsPred'...\nremote: Enumerating objects: 31, done.\u001b[K\nremote: Counting objects: 100% (31/31), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 31 (delta 11), reused 17 (delta 3), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (31/31), 279.39 KiB | 3.45 MiB/s, done.\nResolving deltas: 100% (11/11), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"default_path = \"/kaggle/working/VideoTagsPred\"","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:31:55.649907Z","iopub.execute_input":"2024-09-28T16:31:55.650370Z","iopub.status.idle":"2024-09-28T16:31:55.656119Z","shell.execute_reply.started":"2024-09-28T16:31:55.650318Z","shell.execute_reply":"2024-09-28T16:31:55.654531Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:31:55.657801Z","iopub.execute_input":"2024-09-28T16:31:55.658211Z","iopub.status.idle":"2024-09-28T16:31:56.904706Z","shell.execute_reply.started":"2024-09-28T16:31:55.658165Z","shell.execute_reply":"2024-09-28T16:31:56.903805Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{default_path}/train_data_categories.csv\")[['video_id', 'title', 'description','tags']]\ntaxonomy = pd.read_csv(f\"{default_path}/IAB_tags.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:31:56.907146Z","iopub.execute_input":"2024-09-28T16:31:56.907601Z","iopub.status.idle":"2024-09-28T16:31:56.953056Z","shell.execute_reply.started":"2024-09-28T16:31:56.907566Z","shell.execute_reply":"2024-09-28T16:31:56.952198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df['tags_split'] = df['tags'].str.split(':', expand=False)\n\ndf['tags_1'] = df['tags_split'].apply(lambda x: x[0].strip() if isinstance(x, list) and len(x) > 0 else pd.NA)\ndf['tags_2'] = df['tags_split'].apply(lambda x: x[1].strip() if isinstance(x, list) and len(x) > 1 else pd.NA)\ndf['tags_3'] = df['tags_split'].apply(lambda x: x[2].strip() if isinstance(x, list) and len(x) > 2 else pd.NA)\n\ndf = df.drop('tags_split', axis=1)\n\ndf['tags_2'] = df['tags_2'].replace('', pd.NA)\ndf['tags_3'] = df['tags_3'].replace('', pd.NA)\n\nprint(df[['tags', 'tags_1', 'tags_2', 'tags_3']].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:31:56.954448Z","iopub.execute_input":"2024-09-28T16:31:56.955320Z","iopub.status.idle":"2024-09-28T16:31:56.981340Z","shell.execute_reply.started":"2024-09-28T16:31:56.955268Z","shell.execute_reply":"2024-09-28T16:31:56.980190Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                                tags  \\\n0                   Массовая культура: Юмор и сатира   \n1  События и достопримечательности:  Спортивные с...   \n2  Массовая культура: Отношения знаменитостей, Ма...   \n3     Транспорт, Спорт: Автогонки, Массовая культура   \n4                   Массовая культура: Юмор и сатира   \n\n                            tags_1  \\\n0                Массовая культура   \n1  События и достопримечательности   \n2                Массовая культура   \n3                 Транспорт, Спорт   \n4                Массовая культура   \n\n                                       tags_2                  tags_3  \n0                               Юмор и сатира                    <NA>  \n1       Спортивные события, Массовая культура           Юмор и сатира  \n2  Отношения знаменитостей, Массовая культура  Скандалы знаменитостей  \n3                Автогонки, Массовая культура                    <NA>  \n4                               Юмор и сатира                    <NA>  \n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:31:56.982904Z","iopub.execute_input":"2024-09-28T16:31:56.983408Z","iopub.status.idle":"2024-09-28T16:32:10.428310Z","shell.execute_reply.started":"2024-09-28T16:31:56.983358Z","shell.execute_reply":"2024-09-28T16:32:10.427121Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:10.430460Z","iopub.execute_input":"2024-09-28T16:32:10.430926Z","iopub.status.idle":"2024-09-28T16:32:12.245310Z","shell.execute_reply.started":"2024-09-28T16:32:10.430880Z","shell.execute_reply":"2024-09-28T16:32:12.244177Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=['tags_1'])\ndf = df.reset_index(drop=True)\n\ndf['text'] = 'Title: ' + df['title'] + '\\n\\nDescription: ' + df['description']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:12.246656Z","iopub.execute_input":"2024-09-28T16:32:12.247130Z","iopub.status.idle":"2024-09-28T16:32:12.262139Z","shell.execute_reply.started":"2024-09-28T16:32:12.247096Z","shell.execute_reply":"2024-09-28T16:32:12.261133Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"single_example_classes = df['tags_1'].value_counts()[df['tags_1'].value_counts() == 1].index.tolist()\n\nfor class_name in single_example_classes:\n    row_to_duplicate = df[df['tags_1'] == class_name].iloc[0]\n    df = pd.concat([df, pd.DataFrame([row_to_duplicate])], ignore_index=True)\n\ndf = df.reset_index(drop=True)\n\nprint(f\"Duplicated rows for {len(single_example_classes)} classes with only one example.\")\nprint(f\"New dataset size: {len(df)} rows\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:12.263346Z","iopub.execute_input":"2024-09-28T16:32:12.263707Z","iopub.status.idle":"2024-09-28T16:32:12.351868Z","shell.execute_reply.started":"2024-09-28T16:32:12.263662Z","shell.execute_reply":"2024-09-28T16:32:12.350844Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Duplicated rows for 44 classes with only one example.\nNew dataset size: 1092 rows\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Create label encoding\nunique_labels = sorted(df['tags_1'].unique())\nlabel_to_id = {label: i for i, label in enumerate(unique_labels)}\nlabels = pd.get_dummies(df['tags_1']).astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:12.365689Z","iopub.execute_input":"2024-09-28T16:32:12.366151Z","iopub.status.idle":"2024-09-28T16:32:12.376029Z","shell.execute_reply.started":"2024-09-28T16:32:12.366116Z","shell.execute_reply":"2024-09-28T16:32:12.375218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create label weights\nlabel_weights = 1 - labels.sum() / labels.sum().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:12.377168Z","iopub.execute_input":"2024-09-28T16:32:12.377500Z","iopub.status.idle":"2024-09-28T16:32:12.388888Z","shell.execute_reply.started":"2024-09-28T16:32:12.377466Z","shell.execute_reply":"2024-09-28T16:32:12.387980Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n# Iterative train-test split for unbalanced classes\nfrom skmultilearn.model_selection import iterative_train_test_split\nimport numpy as np\n\nrow_ids = np.arange(len(labels)).reshape(-1, 1)\nX_train, y_train, X_val, y_val = iterative_train_test_split(row_ids, labels.values, test_size=0.1)\n\nx_train = df['text'].iloc[X_train.flatten()].tolist()\nx_val = df['text'].iloc[X_val.flatten()].tolist()\n\ny_train = pd.DataFrame(y_train, columns=labels.columns)\ny_val = pd.DataFrame(y_val, columns=labels.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:19.816082Z","iopub.execute_input":"2024-09-28T16:32:19.817022Z","iopub.status.idle":"2024-09-28T16:32:19.854137Z","shell.execute_reply.started":"2024-09-28T16:32:19.816980Z","shell.execute_reply":"2024-09-28T16:32:19.853180Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n# Convert labels to list of dictionaries\ny_train_dict = y_train.reset_index(drop=True).to_dict('records')\ny_val_dict = y_val.reset_index(drop=True).to_dict('records')\n\n# Create HuggingFace dataset\nds = DatasetDict({\n    'train': Dataset.from_pandas(pd.DataFrame({'text': x_train, 'labels': y_train_dict})),\n    'val': Dataset.from_pandas(pd.DataFrame({'text': x_val, 'labels': y_val_dict}))\n})\n\nprint(f\"Dataset created with {len(ds['train'])} training samples and {len(ds['val'])} validation samples.\")\nprint(f\"Number of unique labels: {len(unique_labels)}\")\nprint(f\"Label weights: {label_weights.values}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:24.498875Z","iopub.execute_input":"2024-09-28T16:32:24.499716Z","iopub.status.idle":"2024-09-28T16:32:24.794727Z","shell.execute_reply.started":"2024-09-28T16:32:24.499679Z","shell.execute_reply":"2024-09-28T16:32:24.793709Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Dataset created with 993 training samples and 99 validation samples.\nNumber of unique labels: 89\nLabel weights: [0.9981685  0.99450549 0.97985348 0.94139194 0.9981685  0.99725275\n 0.99267399 0.9981685  0.9981685  0.9981685  0.9981685  0.9981685\n 0.9981685  0.9981685  0.99542125 0.9981685  0.9981685  0.9981685\n 0.9981685  0.99175824 0.9981685  0.9981685  0.70695971 0.99358974\n 0.99450549 0.9981685  0.9981685  0.96611722 0.99450549 0.9981685\n 0.99725275 0.99175824 0.99725275 0.9981685  0.9981685  0.98168498\n 0.99542125 0.9981685  0.99358974 0.9981685  0.9981685  0.9981685\n 0.99542125 0.9981685  0.97435897 0.9981685  0.99725275 0.9981685\n 0.98168498 0.9981685  0.9981685  0.9981685  0.96336996 0.98717949\n 0.9981685  0.9981685  0.9981685  0.99725275 0.98809524 0.9981685\n 0.98168498 0.96611722 0.9981685  0.9981685  0.92948718 0.98168498\n 0.9981685  0.9981685  0.97435897 0.9981685  0.9981685  0.9981685\n 0.9532967  0.99542125 0.99175824 0.9981685  0.9981685  0.9981685\n 0.99267399 0.9981685  0.99450549 0.9981685  0.9981685  0.98168498\n 0.98168498 0.97710623 0.9981685  0.9981685  0.9981685 ]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install peft\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:27.894611Z","iopub.execute_input":"2024-09-28T16:32:27.895544Z","iopub.status.idle":"2024-09-28T16:32:40.313410Z","shell.execute_reply.started":"2024-09-28T16:32:27.895501Z","shell.execute_reply":"2024-09-28T16:32:40.312110Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:40.315513Z","iopub.execute_input":"2024-09-28T16:32:40.315868Z","iopub.status.idle":"2024-09-28T16:32:56.399315Z","shell.execute_reply.started":"2024-09-28T16:32:40.315833Z","shell.execute_reply":"2024-09-28T16:32:56.397941Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.metrics import f1_score\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom datasets import Dataset, DatasetDict\nfrom peft import (\n    LoraConfig,\n    prepare_model_for_kbit_training,\n    get_peft_model\n)\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:32:56.400895Z","iopub.execute_input":"2024-09-28T16:32:56.401268Z","iopub.status.idle":"2024-09-28T16:33:16.442778Z","shell.execute_reply.started":"2024-09-28T16:32:56.401232Z","shell.execute_reply":"2024-09-28T16:33:16.442000Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:33:16.444529Z","iopub.execute_input":"2024-09-28T16:33:16.445150Z","iopub.status.idle":"2024-09-28T16:33:16.476578Z","shell.execute_reply.started":"2024-09-28T16:33:16.445114Z","shell.execute_reply":"2024-09-28T16:33:16.475639Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6885ab89d7af4c2591e73a969f9e8ce6"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\n\nmodel_id = \"Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:33:26.781900Z","iopub.execute_input":"2024-09-28T16:33:26.782339Z","iopub.status.idle":"2024-09-28T16:37:46.494606Z","shell.execute_reply.started":"2024-09-28T16:33:26.782298Z","shell.execute_reply":"2024-09-28T16:37:46.493625Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/178k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d327231263214a699fd92f5af594ce8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f0b31db66e44c0aa3d926ff5a0a3b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/641 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c51222a96fb4ef684ed49d2f26bbfa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efb5102073504e2495c37ab1ae3a53da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/29.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4583881224240a28bbd30c434a327ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd57135717ee4d15881f889c19223212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82263b71d9db4ac8af4749dd4303965d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d505bd585b341db9b173fd4d708614e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff66b5adbdc848cbbd20dc3409b6776f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a99d98397034911bfb04a364cda4916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"560311e9d7074b9ca86092832c91f2ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf43545f6fd14b70991eaad547862b8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d96bd39f9847fcb3438196335f5b55"}},"metadata":{}}]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    target_modules= [\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:38:00.174963Z","iopub.execute_input":"2024-09-28T16:38:00.175378Z","iopub.status.idle":"2024-09-28T16:38:00.181659Z","shell.execute_reply.started":"2024-09-28T16:38:00.175338Z","shell.execute_reply":"2024-09-28T16:38:00.180342Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    num_labels=labels.shape[1]\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-09-28T16:38:39.996843Z","iopub.execute_input":"2024-09-28T16:38:39.997279Z","iopub.status.idle":"2024-09-28T16:40:13.569006Z","shell.execute_reply.started":"2024-09-28T16:38:39.997240Z","shell.execute_reply":"2024-09-28T16:40:13.567371Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc253f0c16b14afbaff31e81512e0975"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m prepare_model_for_kbit_training(model)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m get_peft_model(model, lora_config)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3960\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3951\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3953\u001b[0m     (\n\u001b[1;32m   3954\u001b[0m         model,\n\u001b[1;32m   3955\u001b[0m         missing_keys,\n\u001b[1;32m   3956\u001b[0m         unexpected_keys,\n\u001b[1;32m   3957\u001b[0m         mismatched_keys,\n\u001b[1;32m   3958\u001b[0m         offload_index,\n\u001b[1;32m   3959\u001b[0m         error_msgs,\n\u001b[0;32m-> 3960\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3980\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4434\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4430\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4431\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4432\u001b[0m                 )\n\u001b[1;32m   4433\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4434\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4436\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4437\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4441\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4442\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4449\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4451\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4453\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:963\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    961\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:217\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.create_quantized_param\u001b[0;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[1;32m    214\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    216\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 217\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:332\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_quantized:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:296\u001b[0m, in \u001b[0;36mParams4bit._quantize\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[0;32m--> 296\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     w_4bit, quant_state \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mquantize_4bit(\n\u001b[1;32m    298\u001b[0m         w,\n\u001b[1;32m    299\u001b[0m         blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m         quant_storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_storage,\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m w_4bit\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 32.12 MiB is free. Process 5254 has 14.71 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 115.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 32.12 MiB is free. Process 5254 has 14.71 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 115.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"code","source":"def tokenize_examples(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['text'])\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\ntokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\ntokenized_ds = tokenized_ds.with_format('torch')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define custom batch preprocessor\ndef collate_fn(batch, tokenizer):\n    dict_keys = ['input_ids', 'attention_mask', 'labels']\n    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n    )\n    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n        d['attention_mask'], batch_first=True, padding_value=0\n    )\n    d['labels'] = torch.stack(d['labels'])\n    return d\n\n# define which metrics to compute for evaluation\ndef compute_metrics(p):\n    predictions, labels = p\n    f1_micro = f1_score(labels, predictions > 0, average = 'micro')\n    f1_macro = f1_score(labels, predictions > 0, average = 'macro')\n    f1_weighted = f1_score(labels, predictions > 0, average = 'weighted')\n    return {\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'f1_weighted': f1_weighted\n    }\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\n# create custom trainer class to be able to pass label weights and calculate mutilabel loss\nclass CustomTrainer(SFTTrainer):\n\n    def __init__(self, label_weights, **kwargs):\n        super().__init__(**kwargs)\n        self.label_weights = label_weights\n    \n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        \n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        \n        # compute custom loss\n        loss = F.binary_cross_entropy_with_logits(logits, labels.to(torch.float32), pos_weight=self.label_weights)\n        return (loss, outputs) if return_outputs else loss\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define training args\ntraining_args = TrainingArguments(\n    output_dir = 'multilabel_classification',\n    learning_rate = 1e-4,\n    per_device_train_batch_size = 8,\n    per_device_eval_batch_size = 8,\n    num_train_epochs = 10,\n    weight_decay = 0.01,\n    evaluation_strategy = 'epoch',\n    save_strategy = 'epoch',\n    load_best_model_at_end = True\n)\n\n# train\ntrainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_ds['train'],\n    eval_dataset = tokenized_ds['val'],\n    tokenizer = tokenizer,\n    data_collator = functools.partial(collate_fn, tokenizer=tokenizer),\n    compute_metrics = compute_metrics,\n    label_weights = torch.tensor(label_weights, device=model.device)\n)\n\ntrainer.train()\n\n# save model\npeft_model_id = 'multilabel_mistral'\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)\n","metadata":{},"execution_count":null,"outputs":[]}]}